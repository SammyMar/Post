---
title: "Testes de hipóteses"
author: "Samuel Martins de Medeiros"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Introdução

De maneira geral, existem duas grandes áreas na inferência Estatística: a estimação de parâmetros, para mais informações sobre estimação, verifique nosso post sobre [função de Verossimilhança](https://observatorioobstetricobr.org/livro-e-tutoriais/funcao-de-verossimilhanca/), e o teste de hipóteses. Em particular, o teste de hipoteses consiste em avaliar uma afirmação a respeito de um parâmetro (média, variância, proporção, etc.) ou um conjunto de parâmetros. Tal afirmação recebe o nome de de Hipótese Nula (Denotado por $H_0$), a afirmação alternativa recebe o nome de Hipótese Alternativa (Denotado por $H_1$).

Para deixar essa ideia um pouco mais clara, suponha que queremos saber se uma determinada marca de blusa *A*, possui um tempo médio de duração (Denotado por $\theta$) igual ou superior a 5 anos. Conseguimos reescrever essa indagação na forma de um sistema de hipóteses, a saber:

```{r echo = F,fig.align = 'center',out.width = 100}
knitr::include_graphics("img/ExemploHipoteses.png")
```

Para realizar o teste, assumimos que é possível obter uma amostra aleatória de blusas da marca *A*, $X_1,...,X_n$, de uma distribuição $f(.;\theta)$.

Tambem é necessário definir a estatística de teste $(T)$ e região de rejeição $(R)$. Estatística de teste é um valor calculado a partir da amostra, seu valor define a regra de rejeição para uma hipótese, ele mostra o quanto seus dados observados correspondem à distribuição esperada sob a hipótese nula desse teste estatístico, denotamos por $R$ os possíveis valores para $\theta$ em que, dado a regra de rejeição, rejeitamos $H_0$.
Estamos interessados em saber se o tempo de duração da marca A é igual ou maior que 5 anos, ou em outras palavras $H_0 : \theta \geq 5$. Um possível teste seria rejeitar $H_0$ se $\overline{x} < 5 - 10/\sqrt{n}$, onde $\overline{x}$ é a estatística de teste $T$, nesse caso nossa estatística acaba por ser o estimador de $\theta$, digamos média amostral. No exemplo em questão, nossa região de rejeição são todos os possíveis valores de $\overline{x} < 5- 10/\sqrt{n}$. Assumiremos $\delta$ como representação do procedimento de testes de hipótese no dercorrer do post.

Um teste pode ser tanto aleatório quanto não aleatório. O exemplo anterior, por exemplo, é um ótimo exemplo de teste não aleatório. Já um teste aleatório poderia ser "jogue uma moeda para o alto, caso cara rejeite a hipótese nula". 

Tão importante quanto conhecer os tipos de teste é a verificação da "qualidade" de um teste, ou o quão correto estamos ao rejeitar uma hipótese.

#### Função Poder e Tipos de Erros\\


Para cada teste aplicado sobre uma amostra obtida de uma distribuição $f(.;\theta)$ onde $\theta \in \Theta$ em que $\Theta$ representa o espaço paramétricos de possíveis valores para $\theta$, teremos uma função poder associada. A função poder define a probabilidade, dado um valor de $\theta$, de rejeitar $H_0$ dado que a mesma é falsa. Suponha um procedimento de teste $\delta$, ou seja, possuímos uma regra de rejeição e uma estatística de teste. A função $\pi(\theta|\delta)$ é chamada função poder do teste $\delta$. Se $S_1$ denota a região de rejeição de $\delta$, então a função poder é determinada pela relação:

```{r echo = F,fig.align = 'left',out.width = 100}
knitr::include_graphics("img/funcaopoder.png")
#<img src="img/funcaopoder.png" width="160"/> 
```

Se $\delta$ é descrito em função da estatística de teste $T$ e da região de rejeição $R$, então

```{r echo = F,fig.align = 'left',out.width = 100}
knitr::include_graphics("img/funcaopoder2.png")
#<img src="img/funcaopoder2.png" width="160"/>
```

para todo $\theta \in \Theta$.

Sendo a função poder, a probabilidade de rejeitar a hipótese nula dado os possíveis valores do parâmetro em estudo $\theta$, buscamos a o teste $\delta$ que minimize $\pi()$ para os valores de $\theta$ pertencentes ao espaço paramétrico de $H_0$ e a maximize quando $\theta$ pertence ao espaço paramétrico de $H_1$, ou em outras palavras, $\pi(\theta \in \Theta_0|\delta) = 0$ e $\pi(\theta \in \Theta_1|\delta) = 1$, onde $\Theta_0$ representa o espaço paramétrico sob a hipótese nula e $\Theta_1$ o espaço paramétrico sob a hipótese alternativa. Retomando o exemplo inicial onde rejeitamos a hipótese nula para $\overline{x} < 5 - 10/\sqrt{n}$, suponha que uma amostra aleatória do produto A, $X_1,...,X_{20}$ foi obtida de uma distribuição Normal$(\theta,\sigma^2)$, com $\sigma^2$ conhecido e igual a 2, onde $\overline{x}$ é o estimador de máxima verossimilhaça para média amostral. Obtendo, assim, a seguinte função poder,

```{r echo = F,fig.align = 'center',out.width = 200}
knitr::include_graphics("img/poderex.png")
#<img src="img/poderex.png" width="300"/>
```

onde $Z$ segue uma distribuição Normal$(0,1)$, obtendo assim:

```{r echo = F,fig.align = 'center',out.width = 200}
knitr::include_graphics("img/podergrafico.png")
#<img src="img/podergrafico.png" width="400"/>
```

Como dito inicialmente, testamos se a hipótese nula é falsa e, portanto, se a hipótese alternativa é verdadeira, ou vice-versa. Nesse contexto, dois tipos de erros podem ser cometidos:

-   Erro do Tipo I: rejeitar a hipótese nula quando a mesma é verdadeira.

-   Erro do Tipo II: aceitar a hipótese nula quando a mesma é falsa.

### Hipótese simples

As hipóteses de um teste podem ser da forma simples ou composta. Uma hipótese simples, é aquela onde o espaço de possíveis valores de $\theta$ é definido em apenas um ponto, onde a distribuição do parâmetro é completamente especificada ($H_0: \theta = \theta_0, f(.;\theta_0)$ por exemplo). Por outro lado, uma hipótese composta é aquela cuja distribuição não é especificada completamente e $\theta$ pode assumir um conjunto de valores $\Theta$ ($H_0: \theta \in \Theta$, $f(.;\Theta)$ por exemplo). A discussão acerca de hipótese simples versus hipótese simples não é muito vista na prática, porém serve como ótima introdução ao tema.

#### Testes de razão de verossimilhança simples

Suponha que $X_1,...,X_n$ uma amostra aleatória de uma distribuição $f_0(.;\theta_0)$ ou $f_1(.;\theta_1)$. Um teste de $H_0: \theta = \theta_0$ vs. $H_1: \theta = \theta_1$ é um teste da razão de verossimilhança se é definido como: onde $k$ é uma constante não negativa e $L(x_1,…,x_n)$ é a função de verossimilhança associada à função de densidade $f(\cdot)$. Rejeitamos a hipótese nula para um valor de $\lambda = L_0(\cdot)/L_1(\cdot)$ inferior a k, pois, seguindo a linha de raciocínio da razão das funções, $L_1(\cdot)$ é maior que $L_0(\cdot)$, nos dando mais indícios de que a amostra venha de uma população com distribuição $f_1(\cdot)$ em vez de uma $f_0(\cdot)$. Exemplo: seja $X_1,…,X_n$ uma amostra aleatória de uma distribuição $N(\theta,1)$ na qual queremos testar $H_0: \theta = 0 \times H_1: \theta = 1$. Tendo a função de verossimilhança como:

```{r echo = F,fig.align = 'center',out.width = 200}
knitr::include_graphics("img/exemplotrv1.png")
#<img src="img/exemplotrv1.png" width="300"/>
```

Obtendo o teste de razão de verossimilhança,

```{r echo = F,fig.align = 'center',out.width = 250}
knitr::include_graphics("img/exemplotrv.png")
#<img src="img/exemplotrv.png" width="400"/>
```

Ou seja, rejeitamos $H_0$ para um somatório de $x$ maior que alguma constante k\*.

#### Testes Mais Poderosos

Antes de falar sobre os testes mais poderosos, uma definição deve ser esclarecida: o tamanho do teste. Vamos admitir um teste $\delta$ cuja hipótese nula seja $H_0: \theta \in \Theta_0$ ($H_0 : \theta < \theta_0$, por exemplo), em que $\theta \subset \Theta_0$ (ou seja, $\Theta_0$ é um subconjunto do espaço paramétrico $\Theta$). Assim, o tamanho do teste é definido como <img src="img/tamanhodoteste.png" width="80"/> . Esclarecida essa definição, daremos prosseguimento ao assunto. Assim como já comentado, queremos um teste $\delta$ em que $\pi(\theta_0|\delta)$ = P[Rejeitar $H_0$ \| $H_0$ verdadeiro] seja a menor possível e que $\pi(\theta_1)$ = P[Rejeitar $H_0$ \| $H_0$ falsa] seja a maior possível. Em um mundo perfeito, $\pi(\theta_1)$ = 1 e $\pi(\theta_0)$ = 0, isto é, quando os erros do tipo I e II são minimizados simultâneamente. Entretanto, na prática, uma das metodologias aplicadas de forma a definir o melhor teste possível é minimizar o erro do tipo II fixando o erro do tipo I.

**Teste Mais Poderoso**: Um teste $\delta*$ em que $H_0: \theta = \theta_0$ contra $H_1: \theta = \theta_1$ é definido como teste mais poderoso de tamanho $\alpha$, com $0 < \alpha < 1$, se e somente se:

i.  $\pi(\theta|\delta*) = \alpha$;

ii. $\pi(\theta_1|\delta*)$ \> $\pi(\theta_1|\delta)$, para qualquer outro teste $\delta$ onde $\pi(\theta_0|\delta)$ \< $\alpha$.

Ou seja, podemos considerar um teste $\delta*$ como sendo o teste mais poderoso se, para qualquer outro teste de tamanho $\alpha$ ou menor do que $\alpha$, ele possuir o maior poder.

O lema (ou método) a seguir é muito útil para encontrar testes mais poderosos.

-   **Lemma Neyman-Pearson:** seja $X_1,...,X_n$ uma amostra aleatória de uma distribuição com densidade $f(x;\theta)$, onde $\theta$ pode assumir os valores $\theta_1$ ou $\theta_0$ e 0 \< $\alpha$ \< 1. Considere $k*$ uma constante positiva e C\* um subconjunto do espaço de valores para $X_i$. Assim,

```{r echo = F,fig.align = 'left',out.width = 120}
knitr::include_graphics("img/lemmapeason1.png")
#<img src="img/lemmapeason1.png" width="250"/>
```

```{r echo = F,fig.align = 'left',out.width = 120}
knitr::include_graphics("img/lemmapearson2.png")
#<img src="img/lemmapearson2.png" width="250"/>
```

e $\lambda$ \> k\* se $(x_1,...,x_n) \in C*$.

Então, considerando um teste de hipóteses simples, temos que o teste para essa região crítica é o teste mais poderoso. Vamos mostrar um exemplo para melhor compreensão.

Exemplo: seja $X_1,...,X_n$ uma amostra aleatória de uma distribuição Bernoulli($\theta$) e seja o teste $H_0:\theta = \theta_0$ vs. $H_1: \theta = \theta_1$, $\theta_1 > \theta_0$. O teste mais poderoso de tamanho $\alpha$ para testar $H_0$ contra $H_1$ é da forma

```{r echo = F,fig.align = 'center',out.width = 210}
knitr::include_graphics("img/neyman1.png")
#<img src="img/neyman1.png" width="350"/>
```

onde $k$ e $\gamma$ é determinada de maneira que <img src="img/neyman2.png" width="110"/>. Agora, se

```{r echo = F,fig.align = 'center',out.width = 130}
knitr::include_graphics("img/neyman3.png")
#<img src="img/neyman3.png" width="220"/>
```

dado que $\theta_1 > \theta_0$ e $\lambda(x)$ é uma função crescente de $\overline{x}_n$,segue que $\lambda(x) > k$ se e somente se $\overline{x}_n > k_1$, sendo $k_1$ uma constante. Então, o teste mais poderoso de tamanho $\alpha$ é da forma

```{r echo = F,fig.align = 'center',out.width = 160}
knitr::include_graphics("img/neyman4.png")
#<img src="img/neyman4.png" width="250"/>
```

Ainda, $k_1$ e $\gamma$ são determinados da forma

```{r echo = F,fig.align = 'center',out.width = 250}
knitr::include_graphics("img/neyman5.png")
#<img src="img/neyman5.png" width="450"/>
```

Observe que o teste mais poderoso de tamanho $\alpha$ é independente de $\theta_1$ quando $\theta_1 > \theta_0$, e é, portanto, o teste mais poderoso para verificar se $\theta = \theta_0$ contra $\theta > \theta_0$.

### Testes para hipóteses compostas

Generalizaremo-los para os teste de hipóteses compostos. A princípio, começaremos com o método mais geral para testar hipóteses, que, geralmente, não é o que fornece resultados mais precisos, mas é aplicável em todo tipo de situação. Considere $X_1,...,X_n$ uma amostra aleatória obtida de uma função de densidade $f(x;\theta)$, $\theta \in \Theta$, e um teste do tipo $H_0: \theta \in \Theta_0$ contra $H_1: \theta \in \Theta_1 = \Theta - \Theta_0$.

-   **Teste de Razão de Verossimilhança Generalizada**: suponha $L(\theta;X_1,...,X_n)$ a função de verossimilhança para a amostra $X_1,...,X_n$. O teste de razão de verossimilhança generalizada, denotado por $\lambda$, é definido como:

```{r echo = F,fig.align = 'center',out.width = 200}
knitr::include_graphics("img/trvg.png")
#<img src="img/trvg.png" width="350"/>
```

onde $\lambda$ se torna uma função da amostra definida no intervalo [0,1]. Assim como no Teste de Razão de Verossimilhança para hipóteses simples, rejeitamos a $H_0$ para algum $\lambda_0 > \lambda$, em que $\lambda_0$ é uma constante definida no intervalo [0,1].

-   **Testes Uniformemente Mais Poderosos (TUMP)**: um teste $\delta*$ do tipo $H_0: \theta \in \Theta_0$ contra $H_1: \theta \in \Theta_1 = \theta - \Theta_0$ é definido como TUMP de tamanho $\alpha$ se e somente se

```{r echo = F,fig.align = 'left',out.width = 110}
knitr::include_graphics("img/ump1.png")
#<img src="img/ump1.png" width="170"/>
```

```{r echo = F,fig.align = 'left',out.width = 110}
knitr::include_graphics("img/ump2.png")
#<img src="img/ump2.png" width="170"/>
```

para todo $\theta \in \Theta - \Theta_0$ e para qualquer teste $\delta$ de tamanho menor ou igual a $\alpha$.

### Conclusão

Na literatura, podemos encontrar formas diferentes de testar hipóteses das vistas neste tutorial, mas elas fogem do escopo deste post e por isso não foram abordadas. Ainda assim, fomos capazes de aprender alguns dos métodos para testar hipóteses estatísticas mais utilizados, além de métodos para achar o melhor tipo de teste. Espero que o texto tenha sido esclarecedor e de ajuda ao leitor. Para mais informações ou dúvidas, escreva-nos em : [comunicacao\@observatorioobstetricobr.org](mailto:comunicacao@observatorioobstetricobr.org){.email}
